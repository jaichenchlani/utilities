{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199a721-db21-476b-a004-80522e6eeb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-cloud-aiplatform\n",
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82d510b-bf80-44b4-b24a-89e8cb59cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import TextGenerationModel, TextEmbeddingModel\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison\")\n",
    "\n",
    "response = model.predict(\n",
    "      '''\n",
    "         List Top 3 DevOps Tools\n",
    "\n",
    "      ''',\n",
    "    temperature=0.1)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d188dc-7e84-47f3-8f4b-5b204d7e08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import VertexAI\n",
    "\n",
    "llm = VertexAI(\n",
    "    model_name='text-bison',\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "prompt = '''\n",
    "         List Top 3 DevOps Tools\n",
    "      '''\n",
    "\n",
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a98a4b-bdc6-49b5-8d56-e1bcd1d77f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = '''\n",
    "\t\tContext: {context}\n",
    "\t\tTask: {task}\n",
    "\t\tFormat: {expected_format}\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['context','task', 'expected_format'],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "context = 'In a world transitioning to sustainable energy'\n",
    "task = 'Explain the benefits and challenges of electric cars'\n",
    "expected_format = 'Provide a balanced analysis, discussing environmental impact, technology, and adoption barriers'\n",
    "\n",
    "final_prompt = prompt.format(context=context, task=task, expected_format=expected_format)\n",
    "\n",
    "print(f'Final Prompt: {final_prompt}')\n",
    "\n",
    "llm(final_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d614ee-ca73-495a-9aba-3eeb4938d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatVertexAI()\n",
    "\n",
    "res = chat(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are Mr Solar System, an expert on Astronomy. You know everything about Solar System. You do NOT anything about topics other than Solar System. You are truthful and never lie. Never make up facts and if you are not 100% sure, reply with why you cannot answer in a truthful way. Respond in short sentences. Shape your response as if talking to a 10-years-old.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"Tell me about pluto?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(res.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636af6cf-d0df-4b86-9bef-7f2646b74712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatVertexAI()\n",
    "\n",
    "res = chat(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are Mr Solar System, an expert on Astronomy. You know everything about Solar System. You do NOT anything about topics other than Solar System. You are truthful and never lie. Never make up facts and if you are not 100% sure, reply with why you cannot answer in a truthful way. Respond in short sentences. Shape your response as if talking to a 10-years-old.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"Tell me about cloud certifications?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(res.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6730a8e6-dca9-401a-b74c-a82f0d180064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "embeddings = VertexAIEmbeddings()\n",
    "\n",
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "\n",
    "print(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a9b43-a446-4ef5-b056-484e78f0a6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
